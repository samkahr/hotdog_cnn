{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageToMatrix (filepath):\n",
    "    images = glob.glob(filepath)\n",
    "    X_list = []\n",
    "    \n",
    "    #looping through images in folder\n",
    "    for myFile in images:\n",
    "      image = cv.imread (myFile)\n",
    "      #feeding in the images resized as 100X100 to reduce the size of the training matrix\n",
    "      resized = cv.resize(image, (100,100), interpolation = cv.INTER_AREA)\n",
    "      #code below changes to image to gray, reducing image color channel to one\n",
    "      color_image = cv.cvtColor(resized, cv.COLOR_BGR2RGB)\n",
    "      gray_image = cv.cvtColor(color_image, cv.COLOR_RGB2GRAY)\n",
    "      X_list.append (gray_image)\n",
    "        \n",
    "    #Transforming list of pixel values into an numpy matrix\n",
    "    \n",
    "    X_data = np.asarray(X_list)\n",
    "    \n",
    "    #normalizing pixel values and converting dtype to value accepted by tensorflow model \n",
    "    X_data = np.array(X_data).astype(np.float32)/255\n",
    "    \n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpgtoMatrix (filename):\n",
    "#     image = cv.imread(UPLOAD_FOLDER+'/'+filename)\n",
    "    image = cv.imread(filename)\n",
    "    X_list = []\n",
    "    resized = cv.resize(image, (100,100), interpolation = cv.INTER_AREA)\n",
    "    color_image = cv.cvtColor(resized, cv.COLOR_BGR2RGB)\n",
    "    gray_image = cv.cvtColor(color_image, cv.COLOR_RGB2GRAY)\n",
    "    X_list.append (gray_image)  \n",
    "    X_data = np.asarray(X_list)\n",
    "    X_data = np.array(X_data).astype(np.float32)/255\n",
    "    \n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since I would like to deploy my app to Google App Engine, which doesn't support cv library, need to create a function \n",
    "#using PIL that will convert images to numpy pixel array that can be fed into TF model. Th\n",
    "\n",
    "def pilMatrix(filepath):\n",
    "\n",
    "    image = Image.open(filepath).convert('L')\n",
    "    \n",
    "    X_list = []\n",
    "    resized = image.resize((100,100), Image.ANTIALIAS)\n",
    "    #need to perform this step so np array is same shape as ML model expects. \n",
    "    resized = np.asarray(resized)\n",
    "    X_list.append (resized)  \n",
    "    X_data = np.asarray(X_list)\n",
    "    X_data = np.array(X_data).astype(np.float32)/255\n",
    "\n",
    "    \n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting training data for hotdog images\n",
    "train_hotdog_dataset = imageToMatrix('./seefood/train/hot_dog/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 100, 100)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hotdog_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating numpy array of labels we can add to final numpy training matrix\n",
    "train_labels_hotdog = np.repeat(1, 249)\n",
    "\n",
    "#converting labels to int32 for TF model\n",
    "train_labels_hotdog = np.array(train_labels_hotdog).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_hotdog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 100, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting training data for not hotdog image\n",
    "train_not_hotdog_dataset = imageToMatrix('./seefood/train/not_hot_dog/*.jpg')\n",
    "\n",
    "train_not_hotdog_lables = np.repeat(0, 249)\n",
    "train_not_hotdog_lables = np.array(train_not_hotdog_lables).astype(np.int32)\n",
    "\n",
    "train_not_hotdog_dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating arrays together to create training data array and \n",
    "#training label array\n",
    "\n",
    "train_data = np.concatenate([train_hotdog_dataset, train_not_hotdog_dataset])\n",
    "train_labels = np.concatenate([train_labels_hotdog, train_not_hotdog_lables])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting index of train data and shuffling it. \n",
    "# In Numpy we can index arrays based on index of other arrays. If we \n",
    "# shuffle index of the train data, we can apply that to our labels \n",
    "# array and both train and label arrays will match up with each other\n",
    "s = np.arange(train_data.shape[0])\n",
    "np.random.shuffle(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying shuffled index to both train and train labels array\n",
    "train_data = train_data[s]\n",
    "train_labels = train_labels[s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now getting test data, note test data has 250 images instead of 249 \n",
    "\n",
    "test_hotdog_data = imageToMatrix('./seefood/test/hot_dog/*.jpg')\n",
    "\n",
    "test_hotdog_labels = np.repeat(1, 250)\n",
    "test_hotdog_labels= np.array(test_hotdog_labels).astype(np.int32)\n",
    "\n",
    "test_not_hotdog_data = imageToMatrix('./seefood/test/not_hot_dog/*.jpg')\n",
    "\n",
    "test_not_hotdog_labels = np.repeat(0, 250)\n",
    "test_not_hotdog_labels= np.array(test_not_hotdog_labels).astype(np.int32)\n",
    "\n",
    "#combining two arrays together\n",
    "\n",
    "test_data = np.concatenate([test_hotdog_data, test_not_hotdog_data])\n",
    "test_labels = np.concatenate([test_hotdog_labels, test_not_hotdog_labels])\n",
    "\n",
    "#shuffling data\n",
    "\n",
    "s = np.arange(test_data.shape[0])\n",
    "np.random.shuffle(s)\n",
    "\n",
    "test_data = test_data[s]\n",
    "test_labels = test_labels[s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the fun stuff! Getting to create our CNN input function for our Tensorflow estimator\n",
    "\n",
    "def cnn_model(features, labels, mode):\n",
    "    #input layer, -1 is batch size treated as hyperparmeter, 100X100 is size of image, 1 is number of color channels\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 100, 100, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5,5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    #convolutional and pooling layer#3 \n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=pool2,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    #convolutional and pooling layer #4 \n",
    "   \n",
    " # Dense Layer\n",
    "    pool4_flat = tf.reshape(pool3, [-1, 12 * 12 * 64])\n",
    "    \n",
    "    dense = tf.layers.dense(inputs=pool4_flat, units=1024, activation=tf.nn.relu)\n",
    "    \n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Hotdog output Layer\n",
    "    hotdogs = tf.layers.dense(inputs=dropout, units=2)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=hotdogs, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(hotdogs, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=hotdogs)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './cnn_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb3a987d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator, specifying input function and where directory \n",
    "# model will be written to\n",
    "hotdog_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model, model_dir=\"./cnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/model.ckpt-1\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./cnn_model/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.48896503 0.51103497]\n",
      " [0.45905164 0.54094833]\n",
      " [0.4731237  0.5268763 ]\n",
      " [0.48483884 0.51516116]\n",
      " [0.4884452  0.51155484]\n",
      " [0.46043143 0.5395686 ]\n",
      " [0.46497652 0.5350235 ]\n",
      " [0.50068367 0.49931636]\n",
      " [0.43304    0.56696   ]\n",
      " [0.48608914 0.51391083]]\n",
      "INFO:tensorflow:loss = 0.7269672, step = 2\n",
      "INFO:tensorflow:Saving checkpoints for 2 into ./cnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.7269672.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0xb3a987a90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input function for training the model \n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=10,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "hotdog_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1, \n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/model.ckpt-2\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2 into ./cnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6803946, step = 3\n",
      "INFO:tensorflow:global_step/sec: 3.43157\n",
      "INFO:tensorflow:loss = 0.67617357, step = 103 (29.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04756\n",
      "INFO:tensorflow:loss = 0.6829586, step = 203 (32.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.41215\n",
      "INFO:tensorflow:loss = 0.67568696, step = 303 (29.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.66268\n",
      "INFO:tensorflow:loss = 0.7082362, step = 403 (37.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.21487\n",
      "INFO:tensorflow:loss = 0.68916714, step = 503 (31.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.20758\n",
      "INFO:tensorflow:loss = 0.6584821, step = 603 (31.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.30353\n",
      "INFO:tensorflow:loss = 0.659733, step = 703 (30.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.28874\n",
      "INFO:tensorflow:loss = 0.68380105, step = 803 (30.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.29062\n",
      "INFO:tensorflow:loss = 0.6455303, step = 903 (30.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.2256\n",
      "INFO:tensorflow:loss = 0.716571, step = 1003 (31.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96183\n",
      "INFO:tensorflow:loss = 0.6644244, step = 1103 (33.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.23527\n",
      "INFO:tensorflow:loss = 0.7141536, step = 1203 (30.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10559\n",
      "INFO:tensorflow:loss = 0.6566667, step = 1303 (32.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.24373\n",
      "INFO:tensorflow:loss = 0.7376806, step = 1403 (30.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.46873\n",
      "INFO:tensorflow:loss = 0.6601294, step = 1503 (40.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.34307\n",
      "INFO:tensorflow:loss = 0.6237651, step = 1603 (42.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9624\n",
      "INFO:tensorflow:loss = 0.62047553, step = 1703 (33.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.68441\n",
      "INFO:tensorflow:loss = 0.5188998, step = 1803 (37.252 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1819 into ./cnn_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.33659\n",
      "INFO:tensorflow:loss = 0.6702477, step = 1903 (29.978 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2002 into ./cnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.6247695.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0xb3a987a90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training step, note we are training locally so only using 2000 epochs\n",
    "hotdog_classifier.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-30T03:42:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/model.ckpt-2002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-30-03:43:00\n",
      "INFO:tensorflow:Saving dict for global step 2002: accuracy = 0.582, global_step = 2002, loss = 0.6802262\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2002: ./cnn_model/model.ckpt-2002\n",
      "{'accuracy': 0.582, 'loss': 0.6802262, 'global_step': 2002}\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Model\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": test_data},\n",
    "    y = test_labels,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "\n",
    "eval_results = hotdog_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets try feeding our model an image of a hotdog and see how it performs\n",
    "hotdog_image = imageToMatrix('./yummyhotdog.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/model.ckpt-2002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classes': 1, 'probabilities': array([0.3631544, 0.6368456], dtype=float32)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a prediction input function for our model. Class = 1 is hotdog, class=2 is not hotdog\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": hotdog_image},\n",
    "    y =None,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "\n",
    "predict = list(hotdog_classifier.predict(predict_input_fn))\n",
    "\n",
    "predict[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets test our model with a not hotdog image from training data \n",
    "not_hotdog = imageToMatrix('./seefood/train/not_hot_dog/6127.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nothotdoginput = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": not_hotdog},\n",
    "    y =None,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/model.ckpt-2002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classes': 0, 'probabilities': array([0.65914315, 0.34085688], dtype=float32)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = list(hotdog_classifier.predict(input_fn=nothotdoginput))\n",
    "\n",
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/model.ckpt-2002\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./saved_model/temp-b'1562014990'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'./saved_model/1562014990'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exporting the TF estimator model so we can host model on Google Cloud AI Platform. We start by defining a input \n",
    "#reciever function then define directory we would like to save model to\n",
    "\n",
    "def serving_input_rec_fn():\n",
    "    #inputs should describe the type of input we are going to serve to model, in this case a numpy array of shape (100, 100, 1)\n",
    "    inputs = {\n",
    "        \"x\": tf.placeholder(tf.float32, [None, 100, 100, 1]), \n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "hotdog_classifier.export_savedmodel(\"./saved_model/\", serving_input_rec_fn,\n",
    "                            strip_default_attrs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
